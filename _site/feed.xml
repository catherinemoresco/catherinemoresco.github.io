<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Catherine Moresco</title>
    <description>Write an awesome description for your new site here. You can edit this line in _config.yml. It will appear in your document head meta (for Google search results) and in your feed.xml site description.
</description>
    <link>http://catmores.co/</link>
    <atom:link href="http://catmores.co/feed.xml" rel="self" type="application/rss+xml" />
    <pubDate>Tue, 16 Dec 2014 16:10:20 -0500</pubDate>
    <lastBuildDate>Tue, 16 Dec 2014 16:10:20 -0500</lastBuildDate>
    <generator>Jekyll v2.4.0</generator>
    
      <item>
        <title>Simple Skew Detection, As Promised</title>
        <description>&lt;p&gt;There&amp;#39;s more than one way to skin a cat...or so I&amp;#39;ve heard. There&amp;#39;s also more than one way to straighten document pages, which is both more fun and more algorithmically complex.&lt;/p&gt;

&lt;p&gt;To understand how to approach this, let&amp;#39;s think about what &amp;quot;straight&amp;quot; means, in this context. To state it most simply: we want the lines of the page to be horizontal. We run into complexities here when we start considering handwritten pages, where lines were written at different varying angles; we also run into problems when lines are curved, as they might be in a photograph of the pages of a thick book. For our purposes, though, we&amp;#39;re going to assuming that the text lines that we are looking at are printed, consistently angled, and mostly linear in form. &lt;/p&gt;

&lt;p&gt;Some text line detection depends on finding these text lines, and then calculating a skew angle based upon them using some basic trigonometry. This seems like a natural way to go about things--how are you supposed to tell if the lines are straight if you dont know where they are?--but text line detection is its own complex beast. Such algorithms will often involve some sort of blurring or thresholding followed by a feature detection algorithm; &lt;a href=&quot;http://www.csse.uwa.edu.au/%7Eshafait/papers/Bukhari-Line-Filters-Text-Line-Detection-ICDAR11.pdf&quot;&gt;this&lt;/a&gt; paper discusses blurring the image while enhancing the texture of the text lines by convolving Gaussian filters with line filters and then using a ride detection algorithm on the image; &lt;a href=&quot;http://www.hpl.hp.com/techreports/94/HPL-94-113.pdf&quot;&gt;this&lt;/a&gt; older paper discusses a different approach that works by accumulation of pixel blobs into sets of text lines based on position. &lt;/p&gt;

&lt;p&gt;But what if we didn&amp;#39;t have to find the lines first? What if we could just manipulate the pixel values into telling us when the page is satisfactorily straight?&lt;/p&gt;

&lt;p&gt;Oh wait...we can.&lt;/p&gt;

&lt;p&gt;(Note: This isn&amp;#39;t a perfect method, but thanks to numpy&amp;#39;s optimized matrix operations on its n-dimensional arrays, it can be quite fast; as long as the initial rotation angle of the page is within 45 degrees of its proper orientation, it will work fairly reliably, no comprehensive testing has been done to determine exact success rates at this time.)&lt;/p&gt;

&lt;p&gt;The idea I started working with is to look at the horizontal sums of pixels across an image. Since each pixel (in a grayscale image) is represented by a single value from 0 (black) to 255 (white), if all the pixels in a row sum to 0 it means that the entire row of pixels is entirely black, and if it is equal to 255 * (width of image), then it is entirely white.&lt;/p&gt;

&lt;p&gt;With this in mind, there are patterns to these pixel values that we can exploit when looking at pages of text. There are, for example, &lt;em&gt;lines.&lt;/em&gt; When these lines intersect horizontal pixel rows at different angles, patterns emerge.&lt;/p&gt;

&lt;p&gt;For example, let&amp;#39;s take a look at this page.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-12-15/samplepage_rotate.jpg&quot; style=&quot;width:400px&quot;&gt;
&lt;/p&gt;

&lt;p&gt;Obviously, not the best rotation angle. If we graph the row sums with the sum along the Y axis and the row number on X axis, it looks like this:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-12-15/colgraph.png&quot; style=&quot;width:400px&quot;&gt;
&lt;/p&gt;

&lt;p&gt;The red line represents the average pixel value.&lt;/p&gt;

&lt;p&gt;We see some features emerge: the areas of text have values clustered rather tightly around a constant value, and the margins and horizontal black lines in those margins are represented by deep spikes and valleys.&lt;/p&gt;

&lt;p&gt;Now, if we rotate the image to its optimal angle, it looks like this:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-12-15/samplepage.jpg&quot; style=&quot;width:400px&quot;&gt;
&lt;/p&gt;
 

&lt;p&gt;And its graph looks like this.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-12-15/rowgraph.png&quot; style=&quot;width:400px&quot;&gt;
&lt;/p&gt;

&lt;p&gt;Really different! At first glance, qualitatively, this new graph looks a whole lot...spikier. There are more discernible hills and valleys, and they are much taller and wider. The valleys represent rows that follow along text lines, and the peaks represent places in which a row cuts between text lines, and is almost entirely white.&lt;/p&gt;

&lt;p&gt;The challenge is coming up with a measure of this &amp;quot;spiky-ness&amp;quot;, and to do that we need to think about the quantitative features of this graph. Is there a good metric for examining the widths and height of these peaks and valleys?&lt;/p&gt;

&lt;p&gt;Well...what about variance? Since the peaks are wide and their slopes are very steep, it means that more points are clustered at the extremes of the light and dark values. &lt;/p&gt;

&lt;p&gt;As a reminder,&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;The variance is the average of the squared deviations from the mean,
    i.e.,  &lt;code&gt;var = mean(abs(x - x.mean())**2)&lt;/code&gt;.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;(From &lt;a href=&quot;https://github.com/numpy/numpy/blob/v1.9.1/numpy/core/fromnumeric.py#L2830&quot;&gt;numpy source&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;Numpy, conveniently, has var() method that will compute the variance of the array of row sums for us, very efficiently. As a measure of how much point values differ, it should suit our needs as a &amp;quot;spikiness&amp;quot; metric. &lt;/p&gt;

&lt;p&gt;This what we utilize in out implementation, iterating through a series of image rotations and calculating the variance of each in an attempt to maximize. &lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;c&quot;&gt;## Iterate through range of angles to find maximum row sum variance&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{}&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;45&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;horizontal_sums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rotate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;angle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())]&lt;/span&gt;
    &lt;span class=&quot;c&quot;&gt;## Iterate through a finer range of values around previous result&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;angle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;angle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;var&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;horizontal_sums&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rotate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;angle&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;variances&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;keys&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;(View the full source &lt;a href=&quot;https://github.com/catherinemoresco/PDFProject/blob/master/pdfproject/skew.py&quot;&gt;here&lt;/a&gt;.)&lt;/p&gt;

&lt;p&gt;This is an implementation that can be optimized further, especially with regard to angle iteration--currently, the algorithm rotates the image 28 times before an optimal value is reached. It may seem inefficient that to rotate the image every time to calculate variance, but numpy&amp;#39;s &lt;code&gt;sum&lt;/code&gt; function can only operate along matrix rows and columns, and accessing individual pixel values in an attempt to approximate sums of a rotated image is highly inefficient.&lt;/p&gt;

&lt;p&gt;Overall, in our (somewhat limited) tests, this algorithm proved to be highly effective. Granted, if given free rein over all possible angles of rotation, it is completely unable to distinguish upside-down text from right-side-up text and it may be fooled by thick dark vertical lines in margins perpendicular to the text; however, as long as it is constrained to angles within 45 degrees of the proper angle, it will usualy find the correct angle, even with embedded pictures.&lt;/p&gt;

&lt;p&gt;To solve the problem of coarse rotation, I added a new page in which the user tells us which way is up:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-12-15/rotate.gif&quot; style=&quot;width:400px&quot;&gt;
&lt;/p&gt;

&lt;p&gt;(It&amp;#39;s smoother in real life, I promise.)&lt;/p&gt;

&lt;p&gt;And there you go! Skew detection reliable enough that I felt comfortable not including a &amp;quot;your algorithm messed up, let me do it myself&amp;quot; button anywhere...like I had to do for line detection.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Last Time:&lt;/em&gt; &lt;a href=&quot;http://catmores.co/pdf/2014/11/19/teaching-my-computer-to-read-not-good-enough.html&quot;&gt;PDF Image Extraction!&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Next time:&lt;/em&gt; Line detection!&lt;/p&gt;
</description>
        <pubDate>Mon, 15 Dec 2014 17:52:30 -0500</pubDate>
        <link>http://catmores.co/pdf/2014/12/15/teaching-my-computer-to-read-skew-detection.html</link>
        <guid isPermaLink="true">http://catmores.co/pdf/2014/12/15/teaching-my-computer-to-read-skew-detection.html</guid>
        
        
        <category>pdf</category>
        
      </item>
    
      <item>
        <title>We&#39;re Already Here</title>
        <description>&lt;p&gt;&lt;strong&gt;“Fuck Catherine, fuck Catherine! No, actually—I REALLY WANT TO FUCK HER.”&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Hi there! I’m Catherine. And that drunken, lustful declaration was how I was welcomed into both life in the dorm I inhabited for the summer and into the tech community at large. It was fun and exciting, like a rite of passage—you can’t really be one of those mythical Women in Tech without being sexually harassed at least once or twice, and here I was, unlocking that achievement in my very first weekend. Afterwards, my (all male) peers who witnessed the event assured me that it was &lt;strong&gt;“definitely a compliment!”&lt;/strong&gt; and that he was &lt;strong&gt;&amp;quot;saying all good things about [me]!”&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;Earlier that same night, I had been invited to a conversation between two young gentlemen about how much better looking I was than this other friend of theirs—she, one of them kindly explained, &lt;strong&gt;“could never get [his] dick hard”&lt;/strong&gt;. I, they assured me, was far, &lt;em&gt;far&lt;/em&gt; more attractive.&lt;/p&gt;

&lt;p&gt;Needless to say, I walked away from that evening struttin’ tall and feelin’ sexy.&lt;/p&gt;

&lt;p&gt;No, just kidding—I went back to my room, cried a little, and avoided everyone for about a week.&lt;/p&gt;

&lt;p&gt;Despite that rough start, I did have a great summer—but it was still punctuated by small incidents, predicated exclusively upon my gender, that made me angry and sad and feel like I didn’t belong. I was the object of domestic violence jokes after innocuously stating that one of my friends had “beaten me” at Magic: The Gathering. I was explicitly told I could not be part of a particular conversation because, in the words of one participant, &amp;quot;we’re all sexist” (and, therefore, incapable of including a female perspective without being offensive—so, I suppose, why try?). In a community that was generally quite supportive—and I did make friendships that I hope will be lifelong ones—interactions like these made me feel…stunned. Sad. Shitty. Even when the people involved were drunk. Even when they were “just kidding.”&lt;/p&gt;

&lt;p&gt;Here’s the thing—the people I’ve had these experiences with are often not vocal misogynists. On the contrary, these are the same men that share links to feminist writings on their Facebook pages and volunteer with Girls Who Code. But calling yourself a feminist does not exempt you from the need for continuous self-examination of your own actions and how they might be affecting those around you, nor does it dissolve the need for a major culture shift before women can feel safe and welcome in the tech community.&lt;/p&gt;

&lt;p&gt;I’ve heard over and over again—from the mouths of VCs and CEOs and my employers and peers alike—that we need to get more Women in Tech, and that desperate attempts are being made to open the eyes of young girls to the world of coding and to welcome them into Tech with open arms.&lt;/p&gt;

&lt;p&gt;Here’s the thing: convincing a girl that coding is fun is not that difficult. Coding is fucking awesome. The first time you make a computer print out “hello world”, it’s magical. You feel powerful. It’s addicting.&lt;/p&gt;

&lt;p&gt;But, as a woman, coding is sometimes the only aspect of my professional experiences that makes me feel powerful—otherwise, even among people who are ostensibly my friends, I have felt alternately angry, sad, unwelcome, and unsafe. When I try to encourage younger girls to develop an interest in programming, as I smile and tell them about all the good bits, I also have to consciously push away the memories I have of being sexually harassed and regularly microaggressed.&lt;/p&gt;

&lt;p&gt;Reasons like this might contribute to the fact that a &lt;a href=&quot;http://www.talentinnovation.org/_private/assets/Athena-2-PressRelease-CTI.pdf&quot;&gt;February 2014 study from the Center for Talent Innovation&lt;/a&gt; found that, in the U.S., women are 45% more likely than men to leave the tech industry within the year. People are incredibly determined to steer young girls into programming careers, yet are incredibly reluctant to behave in a way that makes women who already have programming careers feel safe and welcome. It’s a despicable hypocrisy, and one that I didn’t fully comprehend until I had experienced harassment in a tech environment myself. Throughout my education, people had cheered for and encouraged my patriarchy-smashing choice of career path. Once I began that career, I realized why the encouragement had been necessary—there is internalized misogyny here, and it is evident in pervasive, ubiquitous, grinding ways. &lt;/p&gt;

&lt;p&gt;The problem isn’t just a matter of getting Women into Tech; the problem is keeping them here. And that problem will get a lot better once we face the fact that it exists—and that it demands not only institutional change, but changes in our personal attitudes, our perspectives, and ourselves.&lt;/p&gt;
</description>
        <pubDate>Mon, 24 Nov 2014 07:30:23 -0500</pubDate>
        <link>http://catmores.co/2014/11/24/were-already-here.html</link>
        <guid isPermaLink="true">http://catmores.co/2014/11/24/were-already-here.html</guid>
        
        
      </item>
    
      <item>
        <title>Converting PDF to JPG, Again</title>
        <description>&lt;p&gt;In my &lt;a href=&quot;http://0.0.0.0:4000/cv/pdf/2014/11/12/teaching-my-computer-to-read-pdfs-are-evil.html&quot;&gt;last post&lt;/a&gt;, I talked about how I frantically searched for ways to get my PDFs into JPGs, and how in a caffiene-fueled 4 AM haze I stumbled upon PythonMagick and decided to use it. &lt;/p&gt;

&lt;p&gt;In my last post, I called it &amp;quot;slow&amp;quot; and &amp;quot;ugly&amp;quot; but I didn&amp;#39;t realize how true those words were until I tried to use my image-extracting module into the rest of our application, and started getting outputs like this:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-11-19/imagemagicksucks.jpg&quot;&gt;
&lt;/p&gt;

&lt;p&gt;This is very bad. I don&amp;#39;t think I need to point that out. It&amp;#39;s especially bad when you consider the fact that this level of resolution takes over one second of processing per page to happen (as calculated by my highly scientific, &amp;quot;one-Mississippi-two-Mississippi&amp;quot; counting benchmark method. I would love to run actual tests on performance, but unfortunately this is a project I&amp;#39;m expected to finish within the week.).&lt;/p&gt;

&lt;p&gt;Increasing the image DPI helps, but the result still isn&amp;#39;t antialiased at all, so any result that can be achieved in a reasonable amount of time is going to look pretty bad.&lt;/p&gt;

&lt;p&gt;I figured there might be something in PythonMagick to help me out, so I looked for documentation, only to realize (to my horror) that there actually isn&amp;#39;t a whole lot of it.&lt;/p&gt;

&lt;p&gt;There&amp;#39;s some in the package&amp;#39;s &lt;a href=&quot;http://www.imagemagick.org/download/python/README.txt&quot;&gt;readme&lt;/a&gt;, but it doesn&amp;#39;t seem to be particularly comprehensive; some of the methods I had already been using from some example code I had found on the internet weren&amp;#39;t even there. My alternatives were to try to infer what was going on from the documentation for &lt;a href=&quot;http://www.imagemagick.org/Magick++/Documentation.html&quot;&gt;Magick++&lt;/a&gt;, the C++ API, or to figure it out myself by running&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;PythonMagick&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;dir&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PythonMagick&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and seeing what it spat out. I tried this, and there was (Ah-HAH!) a method called antiAlias--but I gave that a shot, and it didn&amp;#39;t seem capable of operating on PDFs being read; my guess it that is meant for use with drawing functions.&lt;/p&gt;

&lt;p&gt;And that&amp;#39;s where I gave up on ImageMagick. I realized I could either keep on trying to hack togther something with it that would inevitably only increase runtime further, or I could go back to the drawing board.&lt;/p&gt;

&lt;p&gt;I went back to the drawing board. As it turns out, ImageMagick performs its PDF rendering functions with calls to Ghostscript, anyway; I decided to do away with ImageMagick and escape from slow, poorly-documented, impossible-to-install PythonMagick hell by working with Ghostscript directly. Bertan Guven did some &lt;a href=&quot;http://bertanguven.com/faster-conversions-from-pdf-to-pngjpeg-imagemagick-vs-ghostscript/&quot;&gt;more scientific comparisons of Ghostscript and ImageMagick performance&lt;/a&gt;, and his results indicate that Ghostscript is significantly faster.&lt;/p&gt;

&lt;p&gt;Ghostscript doesn&amp;#39;t have Python bindings, so I ran it as a subprocess--and, since we need to process the images after they are extracted (and writing each file and then reading it and then writing it again is definitely not the most efficient way to go about things), I redirected the file output to a buffer.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;getStream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;c&quot;&gt;## run ghostscript command as a subprocess and get output&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;subprocess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Popen&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;gs -dNOPAUSE -sDEVICE=jpeg -sOutputFile=&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;%s&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;tdout -dJPEGQ=100 -r300 -q &amp;quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot; -c quit&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stdout&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;subprocess&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PIPE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shell&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;err&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pipe&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;communicate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;nb&quot;&gt;bytes&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;io&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;BytesIO&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;out&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bytes&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;I only want to make one call to Ghostscript, but I also have multiple images to extract, so we have to parse the resulting byte stream to separate them, and then decode them using OpenCv.&lt;/p&gt;

&lt;p&gt;All JPGs start with &lt;code&gt;b&amp;#39;\xff\xd8&amp;#39;&lt;/code&gt; and end with &lt;code&gt;b&amp;#39;\xff\xd9&amp;#39;&lt;/code&gt;.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extractImages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt; 
        &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;getStream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;filename&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;imgstart&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;imgend&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;

        &lt;span class=&quot;c&quot;&gt;## parse for jpgs&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;decoded_images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_img_start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\xff\xd8&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_img_start&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;next_img_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;find&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;se&quot;&gt;\xff\xd9&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_img_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
                &lt;span class=&quot;k&quot;&gt;break&lt;/span&gt;

            &lt;span class=&quot;c&quot;&gt;## get and decode image bytes&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;decoded_image&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;imdecode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;fromstring&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;stream&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_img_start&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;next_img_end&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;uint8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;cv2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;CV_LOAD_IMAGE_COLOR&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;decoded_images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;decoded_image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;next_img_end&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;decoded_images&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This returns a list of images, which is exactly what my previous implementation did--only this is significantly faster, and doesn&amp;#39;t rely on PythonMagick. &lt;/p&gt;

&lt;p&gt;Here&amp;#39;s a sample result image, rendered at 300 DPI and which ran in a comparable amount of time to our original PythonMagick implementation:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-11-19/ghostscriptisawesome.jpg&quot; style=&quot;height:500px&quot;&gt;
&lt;/p&gt;

&lt;p&gt;I am happy.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Next Time:&lt;/em&gt; &lt;a href=&quot;http://catmores.co/pdf/2014/12/15/teaching-my-computer-to-read-skew-detection.html&quot;&gt;Skew detection&lt;/a&gt;! (For real this time, I promise. Sorry for the digression.)&lt;/p&gt;
</description>
        <pubDate>Wed, 19 Nov 2014 17:52:30 -0500</pubDate>
        <link>http://catmores.co/pdf/2014/11/19/teaching-my-computer-to-read-not-good-enough.html</link>
        <guid isPermaLink="true">http://catmores.co/pdf/2014/11/19/teaching-my-computer-to-read-not-good-enough.html</guid>
        
        
        <category>pdf</category>
        
      </item>
    
      <item>
        <title>Struggles with PDFs and Short-Sightedness</title>
        <description>&lt;p&gt;My favorite computer science classes are the ones that let you build whatever you want. My Introduction to Programming class consisted of a class wiki with student-posted problems, that you could complete whenever you wanted, however you wanted, in whatever language you wanted. It was awesome. &lt;/p&gt;

&lt;p&gt;My class this quarter, Software Construction, has a similar setup, though slightly more structured; working in teams of six, we get to present a proposal, complete with UML use case, class, and activity diagrams, and then implement it and test it rigorously.&lt;/p&gt;

&lt;p&gt;I enjoy messing around with computer vision (that is, after all, why I &lt;a href=&quot;http://catherinemoresco.github.io/projects/&quot;&gt;taught my fish to play Pokemon that one time&lt;/a&gt;), so I decided to do a project that would involve some sweet OpenCV action.
 I also had a lot of readings to do for my philosophy class. Most of these were PDFs of poorly scanned documents. Even when the text lines were miraculously not affected by page curvature, they were often skewed. This is fine for reading, but since they&amp;#39;re just scans they can&amp;#39;t be highlighted in Preview for Mac, so I always have to resort to awkwardly drawing straight boxes around my skewed areas of interest, or spending minutes drawing individual lines under whole paragraphs and minutes more making them consistent in length and width.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt;
&lt;img src=&quot;/img/2014-11-13/Nonideal_page.png&quot;&gt;
&lt;img src=&quot;/img/2014-11-13/Nonideal_boxed.png&quot;&gt;
&lt;img src=&quot;/img/2014-11-13/Nonideal_underlined.png&quot;&gt;
&lt;/p&gt;

&lt;p&gt;&lt;em&gt;How hard could it be,&lt;/em&gt; I thought, &lt;em&gt;to detect the lines and draw the highlights on myself?&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;And, in the meantime, split pages in which there are two book-pages per PDF-page? And maybe rotate the pages ever-so-slightly so that they&amp;#39;re straight again? &lt;/p&gt;

&lt;p&gt;And so my project was born.&lt;/p&gt;

&lt;p&gt;It wasn&amp;#39;t about teaching my computer to read, so much as to teach it the small accessory functions to reading, like straightening a page or laying it flat, without having to go through the trouble of OCR-ing the whole damn thing.&lt;/p&gt;

&lt;p&gt;My first issue, through, was that image processing techniques are (tautologically) meant to process images, and PDFs are not images. In the moment of optimisim upon my conception of the project, this struck me as a trivial problem. After all, scans are just images, right? It can&amp;#39;t be that hard to extract them from their barely-there PDF shell.&lt;/p&gt;

&lt;p&gt;Except it can. Taking apart PDFs is hard. Extracting JPGs from PDFs &lt;em&gt;can&lt;/em&gt; be easy (for example, take a look at &lt;a href=&quot;http://nedbatchelder.com/blog/200712/extracting_jpgs_from_pdfs.html&quot;&gt;Ned Batchelder&amp;#39;s code snippet&lt;/a&gt; that accomplishes this in 20-ish lines of Python), but it can also be hard. As I discovered when I tried to run that same snippet on a few different documents and, to my horror, discovered that there are some images it just doesn&amp;#39;t pick up on. It was then, and only then, (after I had gotten my project proposal approved and convinced some poor souls to hop on board with me) that I stumbled upon this &lt;a href=&quot;https://blog.idrsolutions.com/2010/04/understanding-the-pdf-file-format-how-are-images-stored/&quot;&gt;lovely soul-crushing article&lt;/a&gt;, that kindly broke the news that &amp;quot;if you want to extract images from a PDF, you need to assemble the image from all the raw data – it is not stored as a complete image file you can just rip out.&amp;quot;&lt;/p&gt;

&lt;p&gt;Oops.&lt;/p&gt;

&lt;p&gt;Luckily, there are PDF rendering libraries out there. I spent about eight hours researching them and then four trying to get the one that I decided on, &lt;a href=&quot;http://www.imagemagick.org/&quot;&gt;ImageMagick&lt;/a&gt;, installed properly. That adds up to about twelve hours of seriously considering renaming our endeavor from &amp;quot;The PDF Project&amp;quot; to &amp;quot;Who Needs PDFs Anyway&amp;quot;, and pivoting to work exclusively with tried and true image formats: JPG, PNG. Old friends.&lt;/p&gt;

&lt;p&gt;So...we ended up with something that looks like this.&lt;/p&gt;
&lt;div class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-python&quot; data-lang=&quot;python&quot;&gt;    &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;extractImages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]&lt;/span&gt;

        &lt;span class=&quot;n&quot;&gt;pdf_im&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PyPDF2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;PdfFileReader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;npage&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pdf_im&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;getNumPages&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

        &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;p&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;range&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;npage&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PythonMagick&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Image&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;blob&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;PythonMagick&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Blob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;density&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;75&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;c&quot;&gt;## read in pdf&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;pdf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;+&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;quot;[&amp;quot;&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;str&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;quot;]&amp;quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; 

            &lt;span class=&quot;c&quot;&gt;## write to buffer&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;write&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blob&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;s&quot;&gt;&amp;#39;RGB&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;16&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;rawdata&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;  &lt;span class=&quot;n&quot;&gt;base64&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;b64decode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;blob&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;base64&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt;

            &lt;span class=&quot;c&quot;&gt;## convert raw data to np array&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;np&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ndarray&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;((&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rows&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;columns&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(),&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dtype&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&amp;#39;uint16&amp;#39;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;buffer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rawdata&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;img&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;images&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It&amp;#39;s simple, and slow, and a little ugly, and it brings another third-party dependency into our cobbled-together little app, but it works.&lt;/p&gt;

&lt;p&gt;And that&amp;#39;s my punishment for not doing my research and fully expecting to be able to build a PDF renderer in a week.&lt;/p&gt;

&lt;p&gt;Lesson learned.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Next Time:&lt;/em&gt; We delve into some &lt;em&gt;actual&lt;/em&gt; document analysis with &lt;strong&gt;skew detection!&lt;/strong&gt;&lt;/p&gt;

&lt;div style=&quot;background:#fadbd7;margin:5px -10px 5px -10px;border-radius:4px;padding:10px;&quot;&gt;
&lt;span style=&quot;font-family:Raleway, Open Sans, sans-serif;&quot;&gt;Edit 11/19/14:&lt;/span&gt;
&lt;br&gt;I have since created a considerably improved implementation of rasterizing PDF documents, this time without PythonMagick; it&#39;s described in my next post, &lt;a href=&quot;http://catmores.co/pdf/2014/11/19/teaching-my-computer-to-read-not-good-enough.html&quot;&gt;Teaching My Computer to Read, Part 2: Converting PDF to JPG, Again&lt;/a&gt;.
&lt;/div&gt;

&lt;p&gt;&lt;br&gt;&lt;/p&gt;
</description>
        <pubDate>Thu, 13 Nov 2014 00:11:00 -0500</pubDate>
        <link>http://catmores.co/cv/pdf/2014/11/13/teaching-my-computer-to-read-pdfs-are-evil.html</link>
        <guid isPermaLink="true">http://catmores.co/cv/pdf/2014/11/13/teaching-my-computer-to-read-pdfs-are-evil.html</guid>
        
        
        <category>cv</category>
        
        <category>pdf</category>
        
      </item>
    
      <item>
        <title>On improving</title>
        <description>&lt;p&gt;&lt;em&gt;Perfectionism.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;I&amp;#39;ve always been &amp;quot;good at school&amp;quot;. This isn&amp;#39;t an indicator of genius, but rather one of being quite suited to a system that is very rewarding (and perhaps demanding) of being a perfectionist.&lt;/p&gt;

&lt;p&gt;That&amp;#39;s good and bad. On the one hand, I&amp;#39;m very self-motivated! On the other, when it comes to process that are inherently incremental and reliant upon continuously learning--like, you know, &lt;em&gt;practically everything in the real world&lt;/em&gt;--I sometimes get uncomfortable.&lt;/p&gt;

&lt;p&gt;Schoolwork is extremely modular. You work on a project, you submit it, you get a grade, you move on. You take a test, you submit it, you get a grade, you move on. So, when you walk into that test or sit down to work on that project, there&amp;#39;s an immense amount of pressure to do it right the first time, make it as complete and thorough and perfect as you can, and submit it only when you&amp;#39;re ready.&lt;/p&gt;

&lt;p&gt;Real life isn&amp;#39;t so climactic. For example, this website.&lt;/p&gt;

&lt;p&gt;I spent a lot of my summer building and rebuilding my website--trying to perfect it, trying to figure out which fonts truly &lt;em&gt;embody&lt;/em&gt; my &lt;em&gt;soul&lt;/em&gt; (Raleway won out, but Open Sans will forever be dear to me) and painstakingly adjusting a color scheme, only to then decide that what I had constructed wasn&amp;#39;t perfect, after all.&lt;/p&gt;

&lt;p&gt;And then I realized that I was getting absolutely nowhere. This isn&amp;#39;t a marriage proposal or a down payment on a house, it&amp;#39;s a website. It can change. It can be imperfect, and the journey starting from its imperfections can (and hopefully will) be a valuable one. This scripty font? &lt;em&gt;Why not?&lt;/em&gt; Navy blue? &lt;em&gt;Sure&lt;/em&gt;.&lt;/p&gt;

&lt;p&gt;(Also, I started applying for jobs, and my old website was pretty mediocre, so, you know. Pressure.)&lt;/p&gt;

&lt;p&gt;So here it is: my blog. It&amp;#39;s imperfect, and it&amp;#39;s under construction...and I hope it will be that way for a long time.&lt;/p&gt;
</description>
        <pubDate>Sun, 05 Oct 2014 07:37:00 -0400</pubDate>
        <link>http://catmores.co/2014/10/05/on-improving.html</link>
        <guid isPermaLink="true">http://catmores.co/2014/10/05/on-improving.html</guid>
        
        
      </item>
    
      <item>
        <title>Hello, world!</title>
        <description>&lt;p&gt;Here we are. I have a blog. I am blogging. Hooray!&lt;/p&gt;
</description>
        <pubDate>Tue, 30 Sep 2014 17:50:22 -0400</pubDate>
        <link>http://catmores.co/jekyll/update/2014/09/30/welcome-to-jekyll.html</link>
        <guid isPermaLink="true">http://catmores.co/jekyll/update/2014/09/30/welcome-to-jekyll.html</guid>
        
        
        <category>jekyll</category>
        
        <category>update</category>
        
      </item>
    
  </channel>
</rss>
